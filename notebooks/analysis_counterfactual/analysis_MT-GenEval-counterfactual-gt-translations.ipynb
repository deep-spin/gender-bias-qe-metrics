{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook performs the analysis of the paper on GT translations (counterfactual subset) section 5.2\n",
    "- Just generates and saves the results of the analysis (Error rates, Error rate ratios, QE ratios, statistical significance etc)\n",
    "- Figures and Tables of the paper are generated using these results with notebook: {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import  wilcoxon\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from src import eval_metrics\n",
    "\n",
    "sns.set_theme(\"paper\", style=\"whitegrid\")\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "plt.rcParams[\"grid.color\"] = \"lightgray\"\n",
    "plt.rcParams[\"grid.linestyle\"] = \"--\"\n",
    "plt.rcParams[\"grid.linewidth\"] = 0.5\n",
    "\n",
    "plt.rc(\"text\", usetex=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/amazon-science/machine-translation-gender-eval/blob/main/accuracy_metric.py\n",
    "def get_words(line):\n",
    "    \"\"\"\n",
    "    Helper function to get the set of words in a line.\n",
    "\n",
    "    :param line: Line from which to get the words.\n",
    "    :return: Set of words in the line.\n",
    "    \"\"\"\n",
    "    return set(line.strip().split())\n",
    "\n",
    "\n",
    "def get_trg_correct_incorrect(trg_line, orig_ref, ctf_ref):\n",
    "    \"\"\"\n",
    "    Compute overlap between hyperences and translation\n",
    "    We first get unique words in each of the references w.r.t each other then we compute their overlap with target\n",
    "    \"\"\" \n",
    "    # get words for each segment\n",
    "    trg_words, orig_words, ctf_words = get_words(trg_line), get_words(orig_ref), get_words(ctf_ref)\n",
    "    # get unique words in each of the references\n",
    "    orig_unique = orig_words - ctf_words\n",
    "    ctf_unique = ctf_words - orig_words\n",
    "    # now check the words in the target sentence for overlap with incorrect unique words\n",
    "    trg_correct = trg_words & orig_unique \n",
    "    trg_incorrect = trg_words & ctf_unique\n",
    "    return trg_correct, trg_incorrect \n",
    "\n",
    "\n",
    "def gender_decision(trg_line, orig_ref, ctf_ref):\n",
    "    \"\"\"\n",
    "    Check if gender of a sentence is correct based on corresponding correct and incorrect references.\n",
    "    Algorithm: We make decision based on whether hyp overlaps with original ref and counterfactual ref\n",
    "\n",
    "    :param trg_line: Sentence from translation output for which to check gender.\n",
    "    :param orig_ref: Original (Correct) reference.\n",
    "    :param ctf_ref: Counterfactual reference.\n",
    "    :return: a list of decision, overlap(hyp, original ref), overlap(hyp, counterfactual ref)\n",
    "    \"\"\"\n",
    "    trg_correct, trg_incorrect = get_trg_correct_incorrect(trg_line, orig_ref, ctf_ref)\n",
    "\n",
    "    if trg_incorrect:\n",
    "        decision = 'Incorrect'\n",
    "    else:\n",
    "        decision = 'Correct'\n",
    "\n",
    "    return [decision, trg_correct, trg_incorrect]\n",
    "\n",
    "\n",
    "# def gender_decision_modified(trg_line, orig_ref, ctf_ref):\n",
    "#     \"\"\"\n",
    "#     Check if gender of a sentence is correct based on corresponding correct and incorrect references.\n",
    "#     Algorithm: We make decision based on whether hyp overlaps with original ref and counterfactual ref\n",
    "\n",
    "#     :param trg_line: Sentence from translation output for which to check gender.\n",
    "#     :param orig_ref: Original (Correct) reference.\n",
    "#     :param ctf_ref: Counterfactual reference.\n",
    "#     :return: a list of decision, overlap(hyp, original ref), overlap(hyp, counterfactual ref)\n",
    "#     \"\"\"\n",
    "#     trg_correct, trg_incorrect = get_trg_correct_incorrect(trg_line, orig_ref, ctf_ref)\n",
    "\n",
    "#     if trg_incorrect:\n",
    "#         decision = \"Incorrect\"\n",
    "#     else:\n",
    "#         if trg_correct:\n",
    "#             decision = \"Correct\"\n",
    "#         else:\n",
    "#             decision = \"None\"\n",
    "\n",
    "#     return decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'source_feminine', 'translate_feminine', 'reference_feminine',\n",
      "       'source_masculine', 'translate_masculine', 'reference_masculine',\n",
      "       'hyp_scores_ff', 'hyp_scores_fm', 'hyp_scores_mf', 'hyp_scores_mm',\n",
      "       'scores_f_bleu', 'scores_m_bleu', 'f_quality_bins', 'm_quality_bins',\n",
      "       'decision_f', 'decision_m', 'model', 'lang', 'type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MODELS = {\n",
    "    \"Kiwi 22\": {\n",
    "        \"model_id\": \"Unbabel--wmt22-cometkiwi-da\",\n",
    "        \"type\": \"neural_metric\"\n",
    "    },\n",
    "    \"Kiwi 23 XL\": {\n",
    "        \"model_id\": \"Unbabel--wmt23-cometkiwi-da-xl\",\n",
    "        \"type\": \"neural_metric\"\n",
    "    },\n",
    "    \"Kiwi 23 XXL\": {\n",
    "        \"model_id\": \"Unbabel--wmt23-cometkiwi-da-xxl\",\n",
    "        \"type\": \"neural_metric\"\n",
    "    },\n",
    "    \"xCOMET XL\": {\n",
    "        \"model_id\": \"Unbabel--XCOMET-XL\",\n",
    "        \"type\": \"neural_metric\"\n",
    "    },\n",
    "    \"xCOMET XXL\": {\n",
    "        \"model_id\": \"Unbabel--XCOMET-XXL\",\n",
    "        \"type\": \"neural_metric\"\n",
    "    },\n",
    "    \"MetricX23 LARGE\": {\n",
    "        \"model_id\": \"google--metricx-23-qe-large-v2p0\",\n",
    "        \"type\": \"neural_metric\"\n",
    "    },\n",
    "    \"MetricX23 XL\": {\n",
    "        \"model_id\": \"google--metricx-23-qe-xl-v2p0\",\n",
    "        \"type\": \"neural_metric\"\n",
    "    },\n",
    "}\n",
    "           \n",
    "LANGS = [\"de\",\"ar\",\"it\",\"es\",\"pt\",\"fr\",\"hi\",\"ru\"]\n",
    "\n",
    "tot = list()\n",
    "res_hyp=[]\n",
    "\n",
    "\n",
    "for lang in LANGS:\n",
    "    # open source gender info file\n",
    "    for m, info in MODELS.items():\n",
    "\n",
    "        #first we load the GT translations + the references (these files also contain bleuscores + quality -- these are ignored)\n",
    "        res_hyp=[]\n",
    "        res_hyp = pd.read_csv(f\"./results-copied/scores/nonambiguous-counterfactual/mtgeneval/gt-translations-augmented/{lang}/{info['model_id']}/scores.csv\")\n",
    "        res_hyp[\"decision_f\"] = res_hyp.apply(lambda x: gender_decision(x['translate_feminine'],\n",
    "                                                                                  x['reference_feminine'],\n",
    "                                                                                  x['reference_masculine'])[0], axis=1)\n",
    "        res_hyp[\"decision_m\"] = res_hyp.apply(lambda x: gender_decision(x['translate_masculine'],\n",
    "                                                                                  x['reference_masculine'],\n",
    "                                                                                  x['reference_feminine'])[0], axis=1)\n",
    "        res_hyp[\"model\"] = m\n",
    "        res_hyp[\"lang\"] = lang\n",
    "        res_hyp[\"type\"] = info[\"type\"]\n",
    "        hyp_rename_dict = {\"score_feminine_feminine\":\"hyp_scores_ff\",\n",
    "                            \"score_feminine_masculine\":\"hyp_scores_fm\",\n",
    "                            \"score_masculine_masculine\":\"hyp_scores_mm\",\n",
    "                            \"score_masculine_feminine\":\"hyp_scores_mf\"}\n",
    "        res_hyp = res_hyp.rename(hyp_rename_dict,axis=1)\n",
    "        tot.append(res_hyp)\n",
    "        \n",
    "\n",
    "res = pd.concat(tot)\n",
    "data_all = res\n",
    "print(data_all.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: ar  # 300  samples before taking intersection of models. \n",
      "Language: ar kept # 300  samples (after intersection between all models). \n",
      "Language: de  # 300  samples before taking intersection of models. \n",
      "Language: de kept # 300  samples (after intersection between all models). \n",
      "Language: es  # 300  samples before taking intersection of models. \n",
      "Language: es kept # 300  samples (after intersection between all models). \n",
      "Language: fr  # 300  samples before taking intersection of models. \n",
      "Language: fr kept # 300  samples (after intersection between all models). \n",
      "Language: hi  # 300  samples before taking intersection of models. \n",
      "Language: hi kept # 300  samples (after intersection between all models). \n",
      "Language: it  # 300  samples before taking intersection of models. \n",
      "Language: it kept # 300  samples (after intersection between all models). \n",
      "Language: pt  # 300  samples before taking intersection of models. \n",
      "Language: pt kept # 300  samples (after intersection between all models). \n",
      "Language: ru  # 300  samples before taking intersection of models. \n",
      "Language: ru kept # 300  samples (after intersection between all models). \n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_df = list()\n",
    "original_shapes = {}\n",
    "\n",
    "for (lang, model), subdf in data_all.groupby([\"lang\", \"model\"]):\n",
    "    \n",
    "    original_shape = subdf.shape\n",
    "    # print(lang,model ,original_shape)\n",
    "    if lang not in original_shapes:\n",
    "        original_shapes[lang]=original_shape\n",
    "        \n",
    "    # print(lang, model, original_shape)\n",
    "    filtered = subdf.copy()\n",
    "    filtered = filtered.dropna(subset=[\"hyp_scores_ff\", \"hyp_scores_fm\",\"hyp_scores_mf\",\"hyp_scores_mm\"])\n",
    "   \n",
    "    # rescale scores of LLMs from 0-100 to 0-1\n",
    "    if filtered.iloc[0][\"type\"] == \"LLM\":\n",
    "        filtered[\"hyp_scores_ff\"] = filtered[\"hyp_scores_ff\"] / 100\n",
    "        filtered[\"hyp_scores_fm\"] = filtered[\"hyp_scores_fm\"] / 100\n",
    "        filtered[\"hyp_scores_mm\"] = filtered[\"hyp_scores_mm\"] / 100\n",
    "        filtered[\"hyp_scores_mf\"] = filtered[\"hyp_scores_mf\"] / 100\n",
    "    \n",
    "        # filter out all rows that have scores outside the range [0, 1]\n",
    "        filtered = filtered.loc[\n",
    "            (filtered[\"hyp_scores_ff\"] > 0.1) & \\\n",
    "            (filtered[\"hyp_scores_ff\"] <= 1) & \\\n",
    "            (filtered[\"hyp_scores_fm\"] > 0.1) & \\\n",
    "            (filtered[\"hyp_scores_fm\"] <= 1) & \\\n",
    "            (filtered[\"hyp_scores_mm\"] > 0.1) & \\\n",
    "            (filtered[\"hyp_scores_mm\"] <= 1) & \\\n",
    "            (filtered[\"hyp_scores_mf\"] > 0.1) & \\\n",
    "            (filtered[\"hyp_scores_mf\"] <= 1)\n",
    "        ]\n",
    "    elif \"MetricX\" in filtered.iloc[0][\"model\"]:\n",
    "        filtered[\"hyp_scores_ff\"] = 1 - filtered[\"hyp_scores_ff\"] / 25\n",
    "        filtered[\"hyp_scores_fm\"] = 1 - filtered[\"hyp_scores_fm\"] / 25\n",
    "        filtered[\"hyp_scores_mm\"] = 1 - filtered[\"hyp_scores_mm\"] / 25\n",
    "        filtered[\"hyp_scores_mf\"] = 1 - filtered[\"hyp_scores_mf\"] / 25\n",
    "    else:\n",
    "        #no filtering needed for classical neural metrics!\n",
    "        pass\n",
    "    final_df.append(filtered)\n",
    "\n",
    "data_all = pd.concat(final_df).copy()\n",
    "\n",
    "\n",
    "\n",
    "# Compute the intersection of rows to be kept for each language\n",
    "keep_rows_inter = {}\n",
    "for lang, lang_df in data_all.groupby(\"lang\"):\n",
    "    common_rows = set(lang_df.index)\n",
    "    for model, model_df in lang_df.groupby(\"model\"):\n",
    "        common_rows.intersection_update(set(model_df.index))\n",
    "    keep_rows_inter[lang] = list(common_rows)\n",
    "\n",
    "\n",
    "for lang in keep_rows_inter:\n",
    "    print(f\"Language: {lang}  # {original_shapes[lang][0]}  samples before taking intersection of models. \")\n",
    "    print(f\"Language: {lang} kept # {len(keep_rows_inter[lang])}  samples (after intersection between all models). \")\n",
    "    \n",
    "# then we filter again!\n",
    "final_df=[]\n",
    "removed_info={lang:{} for lang in LANGS}\n",
    "\n",
    "for (lang, model), subdf in data_all.groupby([\"lang\", \"model\"]):\n",
    "    filtered=subdf.copy()\n",
    "    filtered = filtered.loc[keep_rows_inter[lang]]\n",
    "    removed_info[lang][model] =  100 * (1 - filtered.shape[0] / original_shapes[lang][0])\n",
    "\n",
    "    final_df.append(filtered)\n",
    "data_all = pd.concat(final_df).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>ar</th>\n",
       "      <th>it</th>\n",
       "      <th>es</th>\n",
       "      <th>pt</th>\n",
       "      <th>fr</th>\n",
       "      <th>hi</th>\n",
       "      <th>ru</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kiwi 22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kiwi 23 XL</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kiwi 23 XXL</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MetricX23 LARGE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MetricX23 XL</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xCOMET XL</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xCOMET XXL</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  de   ar   it   es   pt   fr   hi   ru\n",
       "Kiwi 22          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "Kiwi 23 XL       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "Kiwi 23 XXL      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "MetricX23 LARGE  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "MetricX23 XL     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "xCOMET XL        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "xCOMET XXL       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removed_info = pd.DataFrame(removed_info)\n",
    "removed_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the data filtering according to received scores, we do a second filtering based on the gender accuracy and quality of GT translations. This involves:\n",
    "\n",
    "- Gender Accuracy (step 1): we verify that both the masculine and feminine GT translations are correctly inflected in terms of gender by comparing them with the corresponding references. We keep samples that have both gender forms correctly inflected.\n",
    "\n",
    "- Quality Match (step 2): We verify that both the masculine and feminine GT translations are of same quality. We use the BLEU lexical overlap based metric to measure the quality of each translation (compute both BLEU(GT_f,h_f) and BLEU(GT_m,h_m))  .  Then we split into quality buckets (according to the obtained BLEU scores)  and we keep the paired samples (s_f,GT_f) and (s_m,GT_m) that (a)  fall into the same quality bucket according to BLEU: BLEU(GT_f,h_f) ~ BLEU(GT_m,h_m) , and (b) the mean bleu scores of the bucket are not significantly different (using wilcoxon test). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- The following cell runs for each lang/QE model language pair and takes into account the samples that:\n",
    "- have the same gender for both translations\n",
    "- are of the same quality (quality bucket)\n",
    "- the mean bleu scores of the bucket are not stat different (ensure good quality for both groups) (according to Wilcoxon Test!)\n",
    "- drops quality buckets with very few samples (less than 10)!\n",
    "\n",
    "\n",
    "We store two dfs:\n",
    "- One with instances the results of the analysis on each quality bucket (quality_bucket_results_df)\n",
    "- and another one (data_df) , that does has the all instances before the analysis (but filtered as explained above). This is in case we want to run an overall analysis for each QE model/lp combination.  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality Bucket kept:   ar Kiwi 22 ('Excellent',) (40, 20)\n",
      "Quality Bucket kept:   ar Kiwi 22 ('Fair',) (32, 20)\n",
      "Quality Bucket kept:   ar Kiwi 22 ('Good',) (20, 20)\n",
      "Quality Bucket kept:   ar Kiwi 22 ('Poor',) (27, 20)\n",
      "Quality Bucket kept:   ar Kiwi 22 ('Useless',) (18, 20)\n",
      "Quality Bucket kept:   ar Kiwi 22 ('Very good',) (17, 20)\n",
      "Quality Bucket kept:   ar Kiwi 23 XL ('Excellent',) (40, 20)\n",
      "Quality Bucket kept:   ar Kiwi 23 XL ('Fair',) (32, 20)\n",
      "Quality Bucket kept:   ar Kiwi 23 XL ('Good',) (20, 20)\n",
      "Quality Bucket kept:   ar Kiwi 23 XL ('Poor',) (27, 20)\n",
      "Quality Bucket kept:   ar Kiwi 23 XL ('Useless',) (18, 20)\n",
      "Quality Bucket kept:   ar Kiwi 23 XL ('Very good',) (17, 20)\n",
      "Quality Bucket kept:   ar Kiwi 23 XXL ('Excellent',) (40, 20)\n",
      "Quality Bucket kept:   ar Kiwi 23 XXL ('Fair',) (32, 20)\n",
      "Quality Bucket kept:   ar Kiwi 23 XXL ('Good',) (20, 20)\n",
      "Quality Bucket kept:   ar Kiwi 23 XXL ('Poor',) (27, 20)\n",
      "Quality Bucket kept:   ar Kiwi 23 XXL ('Useless',) (18, 20)\n",
      "Quality Bucket kept:   ar Kiwi 23 XXL ('Very good',) (17, 20)\n",
      "Quality Bucket kept:   ar MetricX23 LARGE ('Excellent',) (40, 20)\n",
      "Quality Bucket kept:   ar MetricX23 LARGE ('Fair',) (32, 20)\n",
      "Quality Bucket kept:   ar MetricX23 LARGE ('Good',) (20, 20)\n",
      "Quality Bucket kept:   ar MetricX23 LARGE ('Poor',) (27, 20)\n",
      "Quality Bucket kept:   ar MetricX23 LARGE ('Useless',) (18, 20)\n",
      "Quality Bucket kept:   ar MetricX23 LARGE ('Very good',) (17, 20)\n",
      "Quality Bucket kept:   ar MetricX23 XL ('Excellent',) (40, 20)\n",
      "Quality Bucket kept:   ar MetricX23 XL ('Fair',) (32, 20)\n",
      "Quality Bucket kept:   ar MetricX23 XL ('Good',) (20, 20)\n",
      "Quality Bucket kept:   ar MetricX23 XL ('Poor',) (27, 20)\n",
      "Quality Bucket kept:   ar MetricX23 XL ('Useless',) (18, 20)\n",
      "Quality Bucket kept:   ar MetricX23 XL ('Very good',) (17, 20)\n",
      "Quality Bucket kept:   ar xCOMET XL ('Excellent',) (40, 20)\n",
      "Quality Bucket kept:   ar xCOMET XL ('Fair',) (32, 20)\n",
      "Quality Bucket kept:   ar xCOMET XL ('Good',) (20, 20)\n",
      "Quality Bucket kept:   ar xCOMET XL ('Poor',) (27, 20)\n",
      "Quality Bucket kept:   ar xCOMET XL ('Useless',) (18, 20)\n",
      "Quality Bucket kept:   ar xCOMET XL ('Very good',) (17, 20)\n",
      "Quality Bucket kept:   ar xCOMET XXL ('Excellent',) (40, 20)\n",
      "Quality Bucket kept:   ar xCOMET XXL ('Fair',) (32, 20)\n",
      "Quality Bucket kept:   ar xCOMET XXL ('Good',) (20, 20)\n",
      "Quality Bucket kept:   ar xCOMET XXL ('Poor',) (27, 20)\n",
      "Quality Bucket kept:   ar xCOMET XXL ('Useless',) (18, 20)\n",
      "Quality Bucket kept:   ar xCOMET XXL ('Very good',) (17, 20)\n",
      "Quality Bucket kept:   de Kiwi 22 ('Excellent',) (93, 20)\n",
      "Quality Bucket kept:   de Kiwi 22 ('Fair',) (13, 20)\n",
      "Quality Bucket kept:   de Kiwi 22 ('Good',) (17, 20)\n",
      "Very small samples size for: de Kiwi 22 ('Poor',)\n",
      "Very small samples size for: de Kiwi 22 ('Useless',)\n",
      "Quality Bucket kept:   de Kiwi 22 ('Very good',) (30, 20)\n",
      "Quality Bucket kept:   de Kiwi 23 XL ('Excellent',) (93, 20)\n",
      "Quality Bucket kept:   de Kiwi 23 XL ('Fair',) (13, 20)\n",
      "Quality Bucket kept:   de Kiwi 23 XL ('Good',) (17, 20)\n",
      "Very small samples size for: de Kiwi 23 XL ('Poor',)\n",
      "Very small samples size for: de Kiwi 23 XL ('Useless',)\n",
      "Quality Bucket kept:   de Kiwi 23 XL ('Very good',) (30, 20)\n",
      "Quality Bucket kept:   de Kiwi 23 XXL ('Excellent',) (93, 20)\n",
      "Quality Bucket kept:   de Kiwi 23 XXL ('Fair',) (13, 20)\n",
      "Quality Bucket kept:   de Kiwi 23 XXL ('Good',) (17, 20)\n",
      "Very small samples size for: de Kiwi 23 XXL ('Poor',)\n",
      "Very small samples size for: de Kiwi 23 XXL ('Useless',)\n",
      "Quality Bucket kept:   de Kiwi 23 XXL ('Very good',) (30, 20)\n",
      "Quality Bucket kept:   de MetricX23 LARGE ('Excellent',) (93, 20)\n",
      "Quality Bucket kept:   de MetricX23 LARGE ('Fair',) (13, 20)\n",
      "Quality Bucket kept:   de MetricX23 LARGE ('Good',) (17, 20)\n",
      "Very small samples size for: de MetricX23 LARGE ('Poor',)\n",
      "Very small samples size for: de MetricX23 LARGE ('Useless',)\n",
      "Quality Bucket kept:   de MetricX23 LARGE ('Very good',) (30, 20)\n",
      "Quality Bucket kept:   de MetricX23 XL ('Excellent',) (93, 20)\n",
      "Quality Bucket kept:   de MetricX23 XL ('Fair',) (13, 20)\n",
      "Quality Bucket kept:   de MetricX23 XL ('Good',) (17, 20)\n",
      "Very small samples size for: de MetricX23 XL ('Poor',)\n",
      "Very small samples size for: de MetricX23 XL ('Useless',)\n",
      "Quality Bucket kept:   de MetricX23 XL ('Very good',) (30, 20)\n",
      "Quality Bucket kept:   de xCOMET XL ('Excellent',) (93, 20)\n",
      "Quality Bucket kept:   de xCOMET XL ('Fair',) (13, 20)\n",
      "Quality Bucket kept:   de xCOMET XL ('Good',) (17, 20)\n",
      "Very small samples size for: de xCOMET XL ('Poor',)\n",
      "Very small samples size for: de xCOMET XL ('Useless',)\n",
      "Quality Bucket kept:   de xCOMET XL ('Very good',) (30, 20)\n",
      "Quality Bucket kept:   de xCOMET XXL ('Excellent',) (93, 20)\n",
      "Quality Bucket kept:   de xCOMET XXL ('Fair',) (13, 20)\n",
      "Quality Bucket kept:   de xCOMET XXL ('Good',) (17, 20)\n",
      "Very small samples size for: de xCOMET XXL ('Poor',)\n",
      "Very small samples size for: de xCOMET XXL ('Useless',)\n",
      "Quality Bucket kept:   de xCOMET XXL ('Very good',) (30, 20)\n",
      "Quality Bucket kept:   es Kiwi 22 ('Excellent',) (124, 20)\n",
      "Very small samples size for: es Kiwi 22 ('Fair',)\n",
      "Very small samples size for: es Kiwi 22 ('Good',)\n",
      "Very small samples size for: es Kiwi 22 ('Poor',)\n",
      "Quality Bucket kept:   es Kiwi 22 ('Very good',) (22, 20)\n",
      "Quality Bucket kept:   es Kiwi 23 XL ('Excellent',) (124, 20)\n",
      "Very small samples size for: es Kiwi 23 XL ('Fair',)\n",
      "Very small samples size for: es Kiwi 23 XL ('Good',)\n",
      "Very small samples size for: es Kiwi 23 XL ('Poor',)\n",
      "Quality Bucket kept:   es Kiwi 23 XL ('Very good',) (22, 20)\n",
      "Quality Bucket kept:   es Kiwi 23 XXL ('Excellent',) (124, 20)\n",
      "Very small samples size for: es Kiwi 23 XXL ('Fair',)\n",
      "Very small samples size for: es Kiwi 23 XXL ('Good',)\n",
      "Very small samples size for: es Kiwi 23 XXL ('Poor',)\n",
      "Quality Bucket kept:   es Kiwi 23 XXL ('Very good',) (22, 20)\n",
      "Quality Bucket kept:   es MetricX23 LARGE ('Excellent',) (124, 20)\n",
      "Very small samples size for: es MetricX23 LARGE ('Fair',)\n",
      "Very small samples size for: es MetricX23 LARGE ('Good',)\n",
      "Very small samples size for: es MetricX23 LARGE ('Poor',)\n",
      "Quality Bucket kept:   es MetricX23 LARGE ('Very good',) (22, 20)\n",
      "Quality Bucket kept:   es MetricX23 XL ('Excellent',) (124, 20)\n",
      "Very small samples size for: es MetricX23 XL ('Fair',)\n",
      "Very small samples size for: es MetricX23 XL ('Good',)\n",
      "Very small samples size for: es MetricX23 XL ('Poor',)\n",
      "Quality Bucket kept:   es MetricX23 XL ('Very good',) (22, 20)\n",
      "Quality Bucket kept:   es xCOMET XL ('Excellent',) (124, 20)\n",
      "Very small samples size for: es xCOMET XL ('Fair',)\n",
      "Very small samples size for: es xCOMET XL ('Good',)\n",
      "Very small samples size for: es xCOMET XL ('Poor',)\n",
      "Quality Bucket kept:   es xCOMET XL ('Very good',) (22, 20)\n",
      "Quality Bucket kept:   es xCOMET XXL ('Excellent',) (124, 20)\n",
      "Very small samples size for: es xCOMET XXL ('Fair',)\n",
      "Very small samples size for: es xCOMET XXL ('Good',)\n",
      "Very small samples size for: es xCOMET XXL ('Poor',)\n",
      "Quality Bucket kept:   es xCOMET XXL ('Very good',) (22, 20)\n",
      "Quality Bucket kept:   fr Kiwi 22 ('Excellent',) (58, 20)\n",
      "Quality Bucket kept:   fr Kiwi 22 ('Fair',) (23, 20)\n",
      "Quality Bucket kept:   fr Kiwi 22 ('Good',) (24, 20)\n",
      "Quality Bucket kept:   fr Kiwi 22 ('Poor',) (12, 20)\n",
      "Very small samples size for: fr Kiwi 22 ('Useless',)\n",
      "Quality Bucket kept:   fr Kiwi 22 ('Very good',) (31, 20)\n",
      "Quality Bucket kept:   fr Kiwi 23 XL ('Excellent',) (58, 20)\n",
      "Quality Bucket kept:   fr Kiwi 23 XL ('Fair',) (23, 20)\n",
      "Quality Bucket kept:   fr Kiwi 23 XL ('Good',) (24, 20)\n",
      "Quality Bucket kept:   fr Kiwi 23 XL ('Poor',) (12, 20)\n",
      "Very small samples size for: fr Kiwi 23 XL ('Useless',)\n",
      "Quality Bucket kept:   fr Kiwi 23 XL ('Very good',) (31, 20)\n",
      "Quality Bucket kept:   fr Kiwi 23 XXL ('Excellent',) (58, 20)\n",
      "Quality Bucket kept:   fr Kiwi 23 XXL ('Fair',) (23, 20)\n",
      "Quality Bucket kept:   fr Kiwi 23 XXL ('Good',) (24, 20)\n",
      "Quality Bucket kept:   fr Kiwi 23 XXL ('Poor',) (12, 20)\n",
      "Very small samples size for: fr Kiwi 23 XXL ('Useless',)\n",
      "Quality Bucket kept:   fr Kiwi 23 XXL ('Very good',) (31, 20)\n",
      "Quality Bucket kept:   fr MetricX23 LARGE ('Excellent',) (58, 20)\n",
      "Quality Bucket kept:   fr MetricX23 LARGE ('Fair',) (23, 20)\n",
      "Quality Bucket kept:   fr MetricX23 LARGE ('Good',) (24, 20)\n",
      "Quality Bucket kept:   fr MetricX23 LARGE ('Poor',) (12, 20)\n",
      "Very small samples size for: fr MetricX23 LARGE ('Useless',)\n",
      "Quality Bucket kept:   fr MetricX23 LARGE ('Very good',) (31, 20)\n",
      "Quality Bucket kept:   fr MetricX23 XL ('Excellent',) (58, 20)\n",
      "Quality Bucket kept:   fr MetricX23 XL ('Fair',) (23, 20)\n",
      "Quality Bucket kept:   fr MetricX23 XL ('Good',) (24, 20)\n",
      "Quality Bucket kept:   fr MetricX23 XL ('Poor',) (12, 20)\n",
      "Very small samples size for: fr MetricX23 XL ('Useless',)\n",
      "Quality Bucket kept:   fr MetricX23 XL ('Very good',) (31, 20)\n",
      "Quality Bucket kept:   fr xCOMET XL ('Excellent',) (58, 20)\n",
      "Quality Bucket kept:   fr xCOMET XL ('Fair',) (23, 20)\n",
      "Quality Bucket kept:   fr xCOMET XL ('Good',) (24, 20)\n",
      "Quality Bucket kept:   fr xCOMET XL ('Poor',) (12, 20)\n",
      "Very small samples size for: fr xCOMET XL ('Useless',)\n",
      "Quality Bucket kept:   fr xCOMET XL ('Very good',) (31, 20)\n",
      "Quality Bucket kept:   fr xCOMET XXL ('Excellent',) (58, 20)\n",
      "Quality Bucket kept:   fr xCOMET XXL ('Fair',) (23, 20)\n",
      "Quality Bucket kept:   fr xCOMET XXL ('Good',) (24, 20)\n",
      "Quality Bucket kept:   fr xCOMET XXL ('Poor',) (12, 20)\n",
      "Very small samples size for: fr xCOMET XXL ('Useless',)\n",
      "Quality Bucket kept:   fr xCOMET XXL ('Very good',) (31, 20)\n",
      "Quality Bucket kept:   hi Kiwi 22 ('Excellent',) (44, 20)\n",
      "Quality Bucket kept:   hi Kiwi 22 ('Fair',) (18, 20)\n",
      "Quality Bucket kept:   hi Kiwi 22 ('Good',) (12, 20)\n",
      "Quality Bucket kept:   hi Kiwi 22 ('Poor',) (24, 20)\n",
      "Quality Bucket kept:   hi Kiwi 22 ('Useless',) (18, 20)\n",
      "Quality Bucket kept:   hi Kiwi 22 ('Very good',) (13, 20)\n",
      "Quality Bucket kept:   hi Kiwi 23 XL ('Excellent',) (44, 20)\n",
      "Quality Bucket kept:   hi Kiwi 23 XL ('Fair',) (18, 20)\n",
      "Quality Bucket kept:   hi Kiwi 23 XL ('Good',) (12, 20)\n",
      "Quality Bucket kept:   hi Kiwi 23 XL ('Poor',) (24, 20)\n",
      "Quality Bucket kept:   hi Kiwi 23 XL ('Useless',) (18, 20)\n",
      "Quality Bucket kept:   hi Kiwi 23 XL ('Very good',) (13, 20)\n",
      "Quality Bucket kept:   hi Kiwi 23 XXL ('Excellent',) (44, 20)\n",
      "Quality Bucket kept:   hi Kiwi 23 XXL ('Fair',) (18, 20)\n",
      "Quality Bucket kept:   hi Kiwi 23 XXL ('Good',) (12, 20)\n",
      "Quality Bucket kept:   hi Kiwi 23 XXL ('Poor',) (24, 20)\n",
      "Quality Bucket kept:   hi Kiwi 23 XXL ('Useless',) (18, 20)\n",
      "Quality Bucket kept:   hi Kiwi 23 XXL ('Very good',) (13, 20)\n",
      "Quality Bucket kept:   hi MetricX23 LARGE ('Excellent',) (44, 20)\n",
      "Quality Bucket kept:   hi MetricX23 LARGE ('Fair',) (18, 20)\n",
      "Quality Bucket kept:   hi MetricX23 LARGE ('Good',) (12, 20)\n",
      "Quality Bucket kept:   hi MetricX23 LARGE ('Poor',) (24, 20)\n",
      "Quality Bucket kept:   hi MetricX23 LARGE ('Useless',) (18, 20)\n",
      "Quality Bucket kept:   hi MetricX23 LARGE ('Very good',) (13, 20)\n",
      "Quality Bucket kept:   hi MetricX23 XL ('Excellent',) (44, 20)\n",
      "Quality Bucket kept:   hi MetricX23 XL ('Fair',) (18, 20)\n",
      "Quality Bucket kept:   hi MetricX23 XL ('Good',) (12, 20)\n",
      "Quality Bucket kept:   hi MetricX23 XL ('Poor',) (24, 20)\n",
      "Quality Bucket kept:   hi MetricX23 XL ('Useless',) (18, 20)\n",
      "Quality Bucket kept:   hi MetricX23 XL ('Very good',) (13, 20)\n",
      "Quality Bucket kept:   hi xCOMET XL ('Excellent',) (44, 20)\n",
      "Quality Bucket kept:   hi xCOMET XL ('Fair',) (18, 20)\n",
      "Quality Bucket kept:   hi xCOMET XL ('Good',) (12, 20)\n",
      "Quality Bucket kept:   hi xCOMET XL ('Poor',) (24, 20)\n",
      "Quality Bucket kept:   hi xCOMET XL ('Useless',) (18, 20)\n",
      "Quality Bucket kept:   hi xCOMET XL ('Very good',) (13, 20)\n",
      "Quality Bucket kept:   hi xCOMET XXL ('Excellent',) (44, 20)\n",
      "Quality Bucket kept:   hi xCOMET XXL ('Fair',) (18, 20)\n",
      "Quality Bucket kept:   hi xCOMET XXL ('Good',) (12, 20)\n",
      "Quality Bucket kept:   hi xCOMET XXL ('Poor',) (24, 20)\n",
      "Quality Bucket kept:   hi xCOMET XXL ('Useless',) (18, 20)\n",
      "Quality Bucket kept:   hi xCOMET XXL ('Very good',) (13, 20)\n",
      "Quality Bucket kept:   it Kiwi 22 ('Excellent',) (65, 20)\n",
      "Quality Bucket kept:   it Kiwi 22 ('Fair',) (17, 20)\n",
      "Quality Bucket kept:   it Kiwi 22 ('Good',) (22, 20)\n",
      "Quality Bucket kept:   it Kiwi 22 ('Poor',) (15, 20)\n",
      "Very small samples size for: it Kiwi 22 ('Useless',)\n",
      "Quality Bucket kept:   it Kiwi 22 ('Very good',) (28, 20)\n",
      "Quality Bucket kept:   it Kiwi 23 XL ('Excellent',) (65, 20)\n",
      "Quality Bucket kept:   it Kiwi 23 XL ('Fair',) (17, 20)\n",
      "Quality Bucket kept:   it Kiwi 23 XL ('Good',) (22, 20)\n",
      "Quality Bucket kept:   it Kiwi 23 XL ('Poor',) (15, 20)\n",
      "Very small samples size for: it Kiwi 23 XL ('Useless',)\n",
      "Quality Bucket kept:   it Kiwi 23 XL ('Very good',) (28, 20)\n",
      "Quality Bucket kept:   it Kiwi 23 XXL ('Excellent',) (65, 20)\n",
      "Quality Bucket kept:   it Kiwi 23 XXL ('Fair',) (17, 20)\n",
      "Quality Bucket kept:   it Kiwi 23 XXL ('Good',) (22, 20)\n",
      "Quality Bucket kept:   it Kiwi 23 XXL ('Poor',) (15, 20)\n",
      "Very small samples size for: it Kiwi 23 XXL ('Useless',)\n",
      "Quality Bucket kept:   it Kiwi 23 XXL ('Very good',) (28, 20)\n",
      "Quality Bucket kept:   it MetricX23 LARGE ('Excellent',) (65, 20)\n",
      "Quality Bucket kept:   it MetricX23 LARGE ('Fair',) (17, 20)\n",
      "Quality Bucket kept:   it MetricX23 LARGE ('Good',) (22, 20)\n",
      "Quality Bucket kept:   it MetricX23 LARGE ('Poor',) (15, 20)\n",
      "Very small samples size for: it MetricX23 LARGE ('Useless',)\n",
      "Quality Bucket kept:   it MetricX23 LARGE ('Very good',) (28, 20)\n",
      "Quality Bucket kept:   it MetricX23 XL ('Excellent',) (65, 20)\n",
      "Quality Bucket kept:   it MetricX23 XL ('Fair',) (17, 20)\n",
      "Quality Bucket kept:   it MetricX23 XL ('Good',) (22, 20)\n",
      "Quality Bucket kept:   it MetricX23 XL ('Poor',) (15, 20)\n",
      "Very small samples size for: it MetricX23 XL ('Useless',)\n",
      "Quality Bucket kept:   it MetricX23 XL ('Very good',) (28, 20)\n",
      "Quality Bucket kept:   it xCOMET XL ('Excellent',) (65, 20)\n",
      "Quality Bucket kept:   it xCOMET XL ('Fair',) (17, 20)\n",
      "Quality Bucket kept:   it xCOMET XL ('Good',) (22, 20)\n",
      "Quality Bucket kept:   it xCOMET XL ('Poor',) (15, 20)\n",
      "Very small samples size for: it xCOMET XL ('Useless',)\n",
      "Quality Bucket kept:   it xCOMET XL ('Very good',) (28, 20)\n",
      "Quality Bucket kept:   it xCOMET XXL ('Excellent',) (65, 20)\n",
      "Quality Bucket kept:   it xCOMET XXL ('Fair',) (17, 20)\n",
      "Quality Bucket kept:   it xCOMET XXL ('Good',) (22, 20)\n",
      "Quality Bucket kept:   it xCOMET XXL ('Poor',) (15, 20)\n",
      "Very small samples size for: it xCOMET XXL ('Useless',)\n",
      "Quality Bucket kept:   it xCOMET XXL ('Very good',) (28, 20)\n",
      "Quality Bucket kept:   pt Kiwi 22 ('Excellent',) (96, 20)\n",
      "Quality Bucket kept:   pt Kiwi 22 ('Fair',) (15, 20)\n",
      "Quality Bucket kept:   pt Kiwi 22 ('Good',) (13, 20)\n",
      "Quality Bucket kept:   pt Kiwi 22 ('Poor',) (10, 20)\n",
      "Very small samples size for: pt Kiwi 22 ('Useless',)\n",
      "Quality Bucket kept:   pt Kiwi 22 ('Very good',) (26, 20)\n",
      "Quality Bucket kept:   pt Kiwi 23 XL ('Excellent',) (96, 20)\n",
      "Quality Bucket kept:   pt Kiwi 23 XL ('Fair',) (15, 20)\n",
      "Quality Bucket kept:   pt Kiwi 23 XL ('Good',) (13, 20)\n",
      "Quality Bucket kept:   pt Kiwi 23 XL ('Poor',) (10, 20)\n",
      "Very small samples size for: pt Kiwi 23 XL ('Useless',)\n",
      "Quality Bucket kept:   pt Kiwi 23 XL ('Very good',) (26, 20)\n",
      "Quality Bucket kept:   pt Kiwi 23 XXL ('Excellent',) (96, 20)\n",
      "Quality Bucket kept:   pt Kiwi 23 XXL ('Fair',) (15, 20)\n",
      "Quality Bucket kept:   pt Kiwi 23 XXL ('Good',) (13, 20)\n",
      "Quality Bucket kept:   pt Kiwi 23 XXL ('Poor',) (10, 20)\n",
      "Very small samples size for: pt Kiwi 23 XXL ('Useless',)\n",
      "Quality Bucket kept:   pt Kiwi 23 XXL ('Very good',) (26, 20)\n",
      "Quality Bucket kept:   pt MetricX23 LARGE ('Excellent',) (96, 20)\n",
      "Quality Bucket kept:   pt MetricX23 LARGE ('Fair',) (15, 20)\n",
      "Quality Bucket kept:   pt MetricX23 LARGE ('Good',) (13, 20)\n",
      "Quality Bucket kept:   pt MetricX23 LARGE ('Poor',) (10, 20)\n",
      "Very small samples size for: pt MetricX23 LARGE ('Useless',)\n",
      "Quality Bucket kept:   pt MetricX23 LARGE ('Very good',) (26, 20)\n",
      "Quality Bucket kept:   pt MetricX23 XL ('Excellent',) (96, 20)\n",
      "Quality Bucket kept:   pt MetricX23 XL ('Fair',) (15, 20)\n",
      "Quality Bucket kept:   pt MetricX23 XL ('Good',) (13, 20)\n",
      "Quality Bucket kept:   pt MetricX23 XL ('Poor',) (10, 20)\n",
      "Very small samples size for: pt MetricX23 XL ('Useless',)\n",
      "Quality Bucket kept:   pt MetricX23 XL ('Very good',) (26, 20)\n",
      "Quality Bucket kept:   pt xCOMET XL ('Excellent',) (96, 20)\n",
      "Quality Bucket kept:   pt xCOMET XL ('Fair',) (15, 20)\n",
      "Quality Bucket kept:   pt xCOMET XL ('Good',) (13, 20)\n",
      "Quality Bucket kept:   pt xCOMET XL ('Poor',) (10, 20)\n",
      "Very small samples size for: pt xCOMET XL ('Useless',)\n",
      "Quality Bucket kept:   pt xCOMET XL ('Very good',) (26, 20)\n",
      "Quality Bucket kept:   pt xCOMET XXL ('Excellent',) (96, 20)\n",
      "Quality Bucket kept:   pt xCOMET XXL ('Fair',) (15, 20)\n",
      "Quality Bucket kept:   pt xCOMET XXL ('Good',) (13, 20)\n",
      "Quality Bucket kept:   pt xCOMET XXL ('Poor',) (10, 20)\n",
      "Very small samples size for: pt xCOMET XXL ('Useless',)\n",
      "Quality Bucket kept:   pt xCOMET XXL ('Very good',) (26, 20)\n",
      "Quality Bucket kept:   ru Kiwi 22 ('Excellent',) (70, 20)\n",
      "Quality Bucket kept:   ru Kiwi 22 ('Fair',) (17, 20)\n",
      "Quality Bucket kept:   ru Kiwi 22 ('Good',) (24, 20)\n",
      "Quality Bucket kept:   ru Kiwi 22 ('Poor',) (17, 20)\n",
      "Very small samples size for: ru Kiwi 22 ('Useless',)\n",
      "Quality Bucket kept:   ru Kiwi 22 ('Very good',) (24, 20)\n",
      "Quality Bucket kept:   ru Kiwi 23 XL ('Excellent',) (70, 20)\n",
      "Quality Bucket kept:   ru Kiwi 23 XL ('Fair',) (17, 20)\n",
      "Quality Bucket kept:   ru Kiwi 23 XL ('Good',) (24, 20)\n",
      "Quality Bucket kept:   ru Kiwi 23 XL ('Poor',) (17, 20)\n",
      "Very small samples size for: ru Kiwi 23 XL ('Useless',)\n",
      "Quality Bucket kept:   ru Kiwi 23 XL ('Very good',) (24, 20)\n",
      "Quality Bucket kept:   ru Kiwi 23 XXL ('Excellent',) (70, 20)\n",
      "Quality Bucket kept:   ru Kiwi 23 XXL ('Fair',) (17, 20)\n",
      "Quality Bucket kept:   ru Kiwi 23 XXL ('Good',) (24, 20)\n",
      "Quality Bucket kept:   ru Kiwi 23 XXL ('Poor',) (17, 20)\n",
      "Very small samples size for: ru Kiwi 23 XXL ('Useless',)\n",
      "Quality Bucket kept:   ru Kiwi 23 XXL ('Very good',) (24, 20)\n",
      "Quality Bucket kept:   ru MetricX23 LARGE ('Excellent',) (70, 20)\n",
      "Quality Bucket kept:   ru MetricX23 LARGE ('Fair',) (17, 20)\n",
      "Quality Bucket kept:   ru MetricX23 LARGE ('Good',) (24, 20)\n",
      "Quality Bucket kept:   ru MetricX23 LARGE ('Poor',) (17, 20)\n",
      "Very small samples size for: ru MetricX23 LARGE ('Useless',)\n",
      "Quality Bucket kept:   ru MetricX23 LARGE ('Very good',) (24, 20)\n",
      "Quality Bucket kept:   ru MetricX23 XL ('Excellent',) (70, 20)\n",
      "Quality Bucket kept:   ru MetricX23 XL ('Fair',) (17, 20)\n",
      "Quality Bucket kept:   ru MetricX23 XL ('Good',) (24, 20)\n",
      "Quality Bucket kept:   ru MetricX23 XL ('Poor',) (17, 20)\n",
      "Very small samples size for: ru MetricX23 XL ('Useless',)\n",
      "Quality Bucket kept:   ru MetricX23 XL ('Very good',) (24, 20)\n",
      "Quality Bucket kept:   ru xCOMET XL ('Excellent',) (70, 20)\n",
      "Quality Bucket kept:   ru xCOMET XL ('Fair',) (17, 20)\n",
      "Quality Bucket kept:   ru xCOMET XL ('Good',) (24, 20)\n",
      "Quality Bucket kept:   ru xCOMET XL ('Poor',) (17, 20)\n",
      "Very small samples size for: ru xCOMET XL ('Useless',)\n",
      "Quality Bucket kept:   ru xCOMET XL ('Very good',) (24, 20)\n",
      "Quality Bucket kept:   ru xCOMET XXL ('Excellent',) (70, 20)\n",
      "Quality Bucket kept:   ru xCOMET XXL ('Fair',) (17, 20)\n",
      "Quality Bucket kept:   ru xCOMET XXL ('Good',) (24, 20)\n",
      "Quality Bucket kept:   ru xCOMET XXL ('Poor',) (17, 20)\n",
      "Very small samples size for: ru xCOMET XXL ('Useless',)\n",
      "Quality Bucket kept:   ru xCOMET XXL ('Very good',) (24, 20)\n"
     ]
    }
   ],
   "source": [
    "buckets_with_small_sizes = []\n",
    "drop_buckets_bleu = [] #store buckets which have significant stat difference in bleu!\n",
    "\n",
    "keep_instances = []\n",
    "\n",
    "for (lang,model),subdf in data_all.groupby(['lang','model']):\n",
    "    quality_buckets_kept = []\n",
    "    gender_corr = subdf[(subdf['decision_f']==\"Correct\") & (subdf['decision_m']==\"Correct\")]\n",
    "    samples_same_qual = gender_corr[gender_corr[\"f_quality_bins\"] == gender_corr[\"m_quality_bins\"]]\n",
    "\n",
    "    # we check that the bleu scores in each quality bucket dont show any significance difference!\n",
    "    # if they do we throw this samples out!\n",
    "    for quality,qual_df in samples_same_qual.groupby(['f_quality_bins']):\n",
    "        \n",
    "        if qual_df.shape[0]<10:\n",
    "            print(\"Very small samples size for:\", lang,model,quality)\n",
    "            buckets_with_small_sizes.append([lang,model,quality])\n",
    "            continue\n",
    "        s, p_value = wilcoxon(qual_df['scores_f_bleu'], qual_df['scores_m_bleu'],alternative='two-sided')\n",
    "        if p_value<0.05:\n",
    "            drop_buckets_bleu.append(lang,model,quality)\n",
    "        else:\n",
    "            quality_buckets_kept.append(qual_df)\n",
    "            print(\"Quality Bucket kept:  \",lang,model,quality,qual_df.shape)\n",
    "            \n",
    "    merge_quality_buckets = pd.concat(quality_buckets_kept)   \n",
    "    keep_instances.append(merge_quality_buckets) \n",
    "\n",
    "filtered_df = pd.concat(keep_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this filtering process: we compute for each model-language (by assessing the GT translations):\n",
    "- QE ratio denoted as QE_{GT}(s_f,GT_f) / QE_{GT}(s_m,GT_m)  (continuous-analysis results)  + Statistical Significance using 1sample test\n",
    "- The total error rate ER_{GT} (prediction-analysis results) \n",
    "- The error rate ratio between the two gender groups denoted as Φ_{GT} = ER_{GT}(S^F) / ER_{GT}(S^M) (prediction-analysis results) + Statistical Significance using Bootstrap resampling\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kiwi 22 ar (154, 20)\n",
      "Kiwi 23 XL ar (154, 20)\n",
      "Kiwi 23 XXL ar (154, 20)\n",
      "MetricX23 LARGE ar (154, 20)\n",
      "MetricX23 XL ar (154, 20)\n",
      "xCOMET XL ar (154, 20)\n",
      "xCOMET XXL ar (154, 20)\n",
      "Kiwi 22 de (153, 20)\n",
      "Kiwi 23 XL de (153, 20)\n",
      "Kiwi 23 XXL de (153, 20)\n",
      "MetricX23 LARGE de (153, 20)\n",
      "MetricX23 XL de (153, 20)\n",
      "xCOMET XL de (153, 20)\n",
      "xCOMET XXL de (153, 20)\n",
      "Kiwi 22 es (146, 20)\n",
      "Kiwi 23 XL es (146, 20)\n",
      "Kiwi 23 XXL es (146, 20)\n",
      "MetricX23 LARGE es (146, 20)\n",
      "MetricX23 XL es (146, 20)\n",
      "xCOMET XL es (146, 20)\n",
      "xCOMET XXL es (146, 20)\n",
      "Kiwi 22 fr (148, 20)\n",
      "Kiwi 23 XL fr (148, 20)\n",
      "Kiwi 23 XXL fr (148, 20)\n",
      "MetricX23 LARGE fr (148, 20)\n",
      "MetricX23 XL fr (148, 20)\n",
      "xCOMET XL fr (148, 20)\n",
      "xCOMET XXL fr (148, 20)\n",
      "Kiwi 22 hi (129, 20)\n",
      "Kiwi 23 XL hi (129, 20)\n",
      "Kiwi 23 XXL hi (129, 20)\n",
      "MetricX23 LARGE hi (129, 20)\n",
      "MetricX23 XL hi (129, 20)\n",
      "xCOMET XL hi (129, 20)\n",
      "xCOMET XXL hi (129, 20)\n",
      "Kiwi 22 it (147, 20)\n",
      "Kiwi 23 XL it (147, 20)\n",
      "Kiwi 23 XXL it (147, 20)\n",
      "MetricX23 LARGE it (147, 20)\n",
      "MetricX23 XL it (147, 20)\n",
      "xCOMET XL it (147, 20)\n",
      "xCOMET XXL it (147, 20)\n",
      "Kiwi 22 pt (160, 20)\n",
      "Kiwi 23 XL pt (160, 20)\n",
      "Kiwi 23 XXL pt (160, 20)\n",
      "MetricX23 LARGE pt (160, 20)\n",
      "MetricX23 XL pt (160, 20)\n",
      "xCOMET XL pt (160, 20)\n",
      "xCOMET XXL pt (160, 20)\n",
      "Kiwi 22 ru (152, 20)\n",
      "Kiwi 23 XL ru (152, 20)\n",
      "Kiwi 23 XXL ru (152, 20)\n",
      "MetricX23 LARGE ru (152, 20)\n",
      "MetricX23 XL ru (152, 20)\n",
      "xCOMET XL ru (152, 20)\n",
      "xCOMET XXL ru (152, 20)\n"
     ]
    }
   ],
   "source": [
    "continous_results = []\n",
    "prediction_results = []\n",
    "for (lang,model),subdf in filtered_df.groupby(['lang','model']):\n",
    "    print(model,lang,subdf.shape)\n",
    "\n",
    "    #Continuous results -- Compute QE ratio\n",
    "    HYP_qe_ratios,_,HYP_qe_ratios_1sampl_test = eval_metrics.Ratio({\"F\": subdf[\"hyp_scores_ff\"], \"M\": subdf[\"hyp_scores_mm\"]}).score()\n",
    "    d1 = dict(\n",
    "        model=model,\n",
    "        lang=lang,\n",
    "        gt_score_M_mean=subdf[\"hyp_scores_mm\"].mean(),\n",
    "        gt_score_F_mean=subdf[\"hyp_scores_ff\"].mean(),\n",
    "        gt_score_M_std=subdf[\"hyp_scores_mm\"].std(),\n",
    "        gt_score_F_std=subdf[\"hyp_scores_ff\"].std(),\n",
    "        gt_ratio_mean = HYP_qe_ratios.mean(),\n",
    "        gt_ratio_std = HYP_qe_ratios.std(),\n",
    "        gt_significance_ratio = HYP_qe_ratios_1sampl_test \n",
    "    )\n",
    "    continous_results.append(d1)\n",
    "\n",
    "    #hard-prediction-based results -- Compute Error Rate and Error Rate Ratio\n",
    "\n",
    "    F_scores = np.array(pd.concat((subdf[\"hyp_scores_ff\"],subdf[\"hyp_scores_mf\"]),axis=0))\n",
    "    M_scores = np.array(pd.concat((subdf[\"hyp_scores_fm\"],subdf[\"hyp_scores_mm\"]),axis=0))\n",
    "    ground_truth = np.concatenate((np.array([\"female\" for i in range(subdf[\"hyp_scores_ff\"].shape[0])]), np.array([\"male\" for i in range(subdf[\"hyp_scores_mm\"].shape[0])])),axis=0)\n",
    "    acc = eval_metrics.Accuracy({\"F\": F_scores, \"M\": M_scores,\"y_true\": ground_truth}).score()\n",
    "    hyp_group_metrics = eval_metrics.GroupMetricsBootstraping({\"F\": F_scores, \"M\": M_scores,\"y_true\": ground_truth},alternative=\"greater\").stat_significance_with_paired_bootstrap()\n",
    "\n",
    "    d2 = dict(\n",
    "        model=model,\n",
    "        lang=lang,\n",
    "        gt_acc_total = acc,\n",
    "        gt_error_rate_total = hyp_group_metrics[\"results\"][\"total_error_rate\"],\n",
    "        gt_error_rate_male = hyp_group_metrics[\"results\"][\"male\"][\"fnr\"],\n",
    "        gt_error_rate_fem =hyp_group_metrics[\"results\"][\"female\"][\"fnr\"],\n",
    "        gt_error_rate_ratio =  hyp_group_metrics[\"results\"][\"fnr_ratio\"],\n",
    "        gt_stat_significance = hyp_group_metrics[\"stat_significance\"],\n",
    "    )\n",
    "\n",
    "    prediction_results.append(d2)\n",
    "\n",
    "continuous_df = pd.DataFrame(continous_results).reset_index()\n",
    "\n",
    "prediction_df = pd.DataFrame(prediction_results).reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                    False\n",
       "model                    False\n",
       "lang                     False\n",
       "gt_score_M_mean          False\n",
       "gt_score_F_mean          False\n",
       "gt_score_M_std           False\n",
       "gt_score_F_std           False\n",
       "gt_ratio_mean            False\n",
       "gt_ratio_std             False\n",
       "gt_significance_ratio    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for None values:\n",
    "continuous_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                   False\n",
       "model                   False\n",
       "lang                    False\n",
       "gt_acc_total            False\n",
       "gt_error_rate_total     False\n",
       "gt_error_rate_male      False\n",
       "gt_error_rate_fem       False\n",
       "gt_error_rate_ratio     False\n",
       "gt_stat_significance    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_path = './results-copied/stats/nonambiguous-counterfactual/gt-translations/continuous-analysis/results.csv'\n",
    "os.makedirs(os.path.dirname(continuous_path), exist_ok=True)\n",
    "continuous_df.to_csv(continuous_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_path = './results-copied/stats/nonambiguous-counterfactual/gt-translations/prediction-analysis/results.csv'\n",
    "os.makedirs(os.path.dirname(prediction_path), exist_ok=True)\n",
    "prediction_df.to_csv(prediction_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
