{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from src import eval_metrics\n",
    "\n",
    "sns.set_theme(\"paper\", style=\"whitegrid\")\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "plt.rcParams[\"grid.color\"] = \"lightgray\"\n",
    "plt.rcParams[\"grid.linestyle\"] = \"--\"\n",
    "plt.rcParams[\"grid.linewidth\"] = 0.5\n",
    "\n",
    "plt.rc(\"text\", usetex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9248fe80-8407-4489-b071-416881f31398",
   "metadata": {},
   "source": [
    "### Analysis on Reference Translations\n",
    "This part of the notebook saves all the ratios, error rates for the original counterfactual subset, for all the examined metrics on the paper.\n",
    "\n",
    "\n",
    "For the aggregated results over all languages + figures + tables check the make_figs_counterfactual.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3979671c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39c4c6bb-441f-4029-8763-8118f77d995c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>source_feminine</th>\n",
       "      <th>reference_feminine</th>\n",
       "      <th>source_masculine</th>\n",
       "      <th>reference_masculine</th>\n",
       "      <th>ref_scores_ff</th>\n",
       "      <th>ref_scores_fm</th>\n",
       "      <th>ref_scores_mf</th>\n",
       "      <th>ref_scores_mm</th>\n",
       "      <th>model</th>\n",
       "      <th>lang</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Shelton became one of Fort Worth's first femal...</td>\n",
       "      <td>Shelton divenne una delle prime sviluppatrici ...</td>\n",
       "      <td>Shelton became one of Fort Worth's first male ...</td>\n",
       "      <td>Shelton divenne uno dei primi sviluppatori imm...</td>\n",
       "      <td>0.866541</td>\n",
       "      <td>0.759603</td>\n",
       "      <td>0.695609</td>\n",
       "      <td>0.844132</td>\n",
       "      <td>Kiwi 22</td>\n",
       "      <td>it</td>\n",
       "      <td>neural_metric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>My mom played for Leinster, my aunt played for...</td>\n",
       "      <td>Mia madre, mia zia, mio cugina hanno giocato n...</td>\n",
       "      <td>My dad played for Leinster, my uncle played fo...</td>\n",
       "      <td>Mio padre, mio zio, mio cugino hanno giocato n...</td>\n",
       "      <td>0.871331</td>\n",
       "      <td>0.865184</td>\n",
       "      <td>0.863381</td>\n",
       "      <td>0.882993</td>\n",
       "      <td>Kiwi 22</td>\n",
       "      <td>it</td>\n",
       "      <td>neural_metric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>In 1512, as papal legate for Italy and Germany...</td>\n",
       "      <td>Nel 1512, come legato pontificio per l'Italia ...</td>\n",
       "      <td>In 1512, as papal legate for Italy and Germany...</td>\n",
       "      <td>Nel 1512, come legato pontificio per l'Italia ...</td>\n",
       "      <td>0.879873</td>\n",
       "      <td>0.817564</td>\n",
       "      <td>0.823342</td>\n",
       "      <td>0.881579</td>\n",
       "      <td>Kiwi 22</td>\n",
       "      <td>it</td>\n",
       "      <td>neural_metric</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                    source_feminine  \\\n",
       "0   0  Shelton became one of Fort Worth's first femal...   \n",
       "1   1  My mom played for Leinster, my aunt played for...   \n",
       "2   2  In 1512, as papal legate for Italy and Germany...   \n",
       "\n",
       "                                  reference_feminine  \\\n",
       "0  Shelton divenne una delle prime sviluppatrici ...   \n",
       "1  Mia madre, mia zia, mio cugina hanno giocato n...   \n",
       "2  Nel 1512, come legato pontificio per l'Italia ...   \n",
       "\n",
       "                                    source_masculine  \\\n",
       "0  Shelton became one of Fort Worth's first male ...   \n",
       "1  My dad played for Leinster, my uncle played fo...   \n",
       "2  In 1512, as papal legate for Italy and Germany...   \n",
       "\n",
       "                                 reference_masculine  ref_scores_ff  \\\n",
       "0  Shelton divenne uno dei primi sviluppatori imm...       0.866541   \n",
       "1  Mio padre, mio zio, mio cugino hanno giocato n...       0.871331   \n",
       "2  Nel 1512, come legato pontificio per l'Italia ...       0.879873   \n",
       "\n",
       "   ref_scores_fm  ref_scores_mf  ref_scores_mm    model lang           type  \n",
       "0       0.759603       0.695609       0.844132  Kiwi 22   it  neural_metric  \n",
       "1       0.865184       0.863381       0.882993  Kiwi 22   it  neural_metric  \n",
       "2       0.817564       0.823342       0.881579  Kiwi 22   it  neural_metric  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "MODELS = {\n",
    "    \"Kiwi 22\": {\n",
    "        \"model_id\": \"Unbabel--wmt22-cometkiwi-da\",\n",
    "        \"type\": \"neural_metric\"\n",
    "    },\n",
    "    \"Kiwi 23 XL\": {\n",
    "        \"model_id\": \"Unbabel--wmt23-cometkiwi-da-xl\",\n",
    "        \"type\": \"neural_metric\"\n",
    "    },\n",
    "    \"Kiwi 23 XXL\": {\n",
    "        \"model_id\": \"Unbabel--wmt23-cometkiwi-da-xxl\",\n",
    "        \"type\": \"neural_metric\"\n",
    "    },\n",
    "    \"xCOMET XL\": {\n",
    "        \"model_id\": \"Unbabel--XCOMET-XL\",\n",
    "        \"type\": \"neural_metric\"\n",
    "    },\n",
    "    \"xCOMET XXL\": {\n",
    "        \"model_id\": \"Unbabel--XCOMET-XXL\",\n",
    "        \"type\": \"neural_metric\"\n",
    "    },\n",
    "    \"MetricX23 LARGE\": {\n",
    "        \"model_id\": \"google--metricx-23-qe-large-v2p0\",\n",
    "        \"type\": \"neural_metric\"\n",
    "    },\n",
    "    \"MetricX23 XL\": {\n",
    "        \"model_id\": \"google--metricx-23-qe-xl-v2p0\",\n",
    "        \"type\": \"neural_metric\"\n",
    "    },\n",
    "\n",
    "    \"Llama 3.1 70B\": {\n",
    "        \"model_id\": \"meta-llama--Meta-Llama-3.1-70B-Instruct\",\n",
    "        \"type\": \"LLM\"\n",
    "    },\n",
    "    \n",
    "    \"Mistral 7B\": {\n",
    "        \"model_id\": \"mistralai--Mistral-7B-Instruct-v0.2\",\n",
    "        \"type\": \"LLM\"\n",
    "    },\n",
    "    \"Gemma 2 9B\": {\n",
    "        \"model_id\": \"google--gemma-2-9b-it\",\n",
    "        \"type\": \"LLM\"\n",
    "    },\n",
    "    \"GPT 4\": {\n",
    "    \"model_id\": \"gpt-4o-2024-05-13\",\n",
    "    \"type\": \"LLM\"\n",
    "    }\n",
    "    \n",
    "}\n",
    "           \n",
    "LANGS = [\"it\",\"es\",\"de\",\"pt\",\"ar\",\"fr\",\"hi\",\"ru\"]\n",
    "\n",
    "tot = list()\n",
    "\n",
    "\n",
    "\n",
    "for lang in LANGS:\n",
    "    # open source gender info file\n",
    "    for m, info in MODELS.items():\n",
    "        res_ref = pd.read_csv(f\"./results-copied/scores/nonambiguous-counterfactual/mtgeneval/references/{lang}/{info['model_id']}/scores.csv\")\n",
    "        res_ref[\"model\"] = m\n",
    "        res_ref[\"lang\"] = lang\n",
    "        res_ref[\"type\"] = info[\"type\"]\n",
    "        ref_rename_dict = {\"score_feminine_feminine\":\"ref_scores_ff\",\"score_feminine_masculine\":\"ref_scores_fm\",\"score_masculine_masculine\":\"ref_scores_mm\",\"score_masculine_feminine\":\"ref_scores_mf\",}\n",
    "        res_ref = res_ref.rename(ref_rename_dict,axis=1).copy()\n",
    "        tot.append(res_ref)\n",
    "        \n",
    "res = pd.concat(tot)\n",
    "data_all = res\n",
    "\n",
    "data_all.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4bc15dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: ar  # 300  samples before taking intersection of models. \n",
      "Language: ar kept # 229  samples (after intersection between all models). \n",
      "Language: de  # 300  samples before taking intersection of models. \n",
      "Language: de kept # 222  samples (after intersection between all models). \n",
      "Language: es  # 300  samples before taking intersection of models. \n",
      "Language: es kept # 240  samples (after intersection between all models). \n",
      "Language: fr  # 300  samples before taking intersection of models. \n",
      "Language: fr kept # 255  samples (after intersection between all models). \n",
      "Language: hi  # 300  samples before taking intersection of models. \n",
      "Language: hi kept # 271  samples (after intersection between all models). \n",
      "Language: it  # 300  samples before taking intersection of models. \n",
      "Language: it kept # 243  samples (after intersection between all models). \n",
      "Language: pt  # 300  samples before taking intersection of models. \n",
      "Language: pt kept # 221  samples (after intersection between all models). \n",
      "Language: ru  # 300  samples before taking intersection of models. \n",
      "Language: ru kept # 236  samples (after intersection between all models). \n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_df = list()\n",
    "original_shapes = {}\n",
    "\n",
    "for (lang, model), subdf in data_all.groupby([\"lang\", \"model\"]):\n",
    "    \n",
    "    original_shape = subdf.shape\n",
    "    # print(lang,model ,original_shape)\n",
    "    if lang not in original_shapes:\n",
    "        original_shapes[lang]=original_shape\n",
    "        \n",
    "    # print(lang, model, original_shape)\n",
    "    filtered = subdf.copy()\n",
    "    filtered = filtered.dropna(subset=[\"ref_scores_ff\", \"ref_scores_fm\",\"ref_scores_mf\",\"ref_scores_mm\"])\n",
    "   \n",
    "    # rescale scores of LLMs from 0-100 to 0-1\n",
    "    if filtered.iloc[0][\"type\"] == \"LLM\":\n",
    "        filtered[\"ref_scores_ff\"] = filtered[\"ref_scores_ff\"] / 100\n",
    "        filtered[\"ref_scores_fm\"] = filtered[\"ref_scores_fm\"] / 100\n",
    "        filtered[\"ref_scores_mm\"] = filtered[\"ref_scores_mm\"] / 100\n",
    "        filtered[\"ref_scores_mf\"] = filtered[\"ref_scores_mf\"] / 100\n",
    "    \n",
    "        # filter out all rows that have scores outside the range [0, 1]\n",
    "        filtered = filtered.loc[\n",
    "            (filtered[\"ref_scores_ff\"] > 0.1) & \\\n",
    "            (filtered[\"ref_scores_ff\"] <= 1) & \\\n",
    "            (filtered[\"ref_scores_fm\"] > 0.1) & \\\n",
    "            (filtered[\"ref_scores_fm\"] <= 1) & \\\n",
    "            (filtered[\"ref_scores_mm\"] > 0.1) & \\\n",
    "            (filtered[\"ref_scores_mm\"] <= 1) & \\\n",
    "            (filtered[\"ref_scores_mf\"] > 0.1) & \\\n",
    "            (filtered[\"ref_scores_mf\"] <= 1)\n",
    "        ]\n",
    "    elif \"MetricX\" in filtered.iloc[0][\"model\"]:\n",
    "        filtered[\"ref_scores_ff\"] = 1 - filtered[\"ref_scores_ff\"] / 25\n",
    "        filtered[\"ref_scores_fm\"] = 1 - filtered[\"ref_scores_fm\"] / 25\n",
    "        filtered[\"ref_scores_mm\"] = 1 - filtered[\"ref_scores_mm\"] / 25\n",
    "        filtered[\"ref_scores_mf\"] = 1 - filtered[\"ref_scores_mf\"] / 25\n",
    "    else:\n",
    "        #no filtering needed for classical neural metrics!\n",
    "        pass\n",
    "    final_df.append(filtered)\n",
    "\n",
    "data_all = pd.concat(final_df).copy()\n",
    "\n",
    "\n",
    "\n",
    "# Compute the intersection of rows to be kept for each language\n",
    "keep_rows_inter = {}\n",
    "for lang, lang_df in data_all.groupby(\"lang\"):\n",
    "    common_rows = set(lang_df.index)\n",
    "    for model, model_df in lang_df.groupby(\"model\"):\n",
    "        common_rows.intersection_update(set(model_df.index))\n",
    "    keep_rows_inter[lang] = list(common_rows)\n",
    "\n",
    "for lang in keep_rows_inter:\n",
    "    print(f\"Language: {lang}  # {original_shapes[lang][0]}  samples before taking intersection of models. \")\n",
    "    print(f\"Language: {lang} kept # {len(keep_rows_inter[lang])}  samples (after intersection between all models). \")\n",
    "\n",
    "\n",
    "# then we filter again!\n",
    "final_df=[]\n",
    "removed_info={lang:{} for lang in LANGS}\n",
    "\n",
    "for (lang, model), subdf in data_all.groupby([\"lang\", \"model\"]):\n",
    "    filtered=subdf.copy()\n",
    "    filtered = filtered.loc[keep_rows_inter[lang]]\n",
    "    removed_info[lang][model] =  100 * (1 - filtered.shape[0] / original_shapes[lang][0])\n",
    "\n",
    "    final_df.append(filtered)\n",
    "data_all = pd.concat(final_df).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68351a9f-9dc6-4676-a1e2-29f9f2ddb91a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>it</th>\n",
       "      <th>es</th>\n",
       "      <th>de</th>\n",
       "      <th>pt</th>\n",
       "      <th>ar</th>\n",
       "      <th>fr</th>\n",
       "      <th>hi</th>\n",
       "      <th>ru</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GPT 4</th>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>21.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gemma 2 9B</th>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>21.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kiwi 22</th>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>21.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kiwi 23 XL</th>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>21.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kiwi 23 XXL</th>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>21.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama 3.1 70B</th>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>21.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MetricX23 LARGE</th>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>21.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MetricX23 XL</th>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>21.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral 7B</th>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>21.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xCOMET XL</th>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>21.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xCOMET XXL</th>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>21.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   it    es    de         pt         ar    fr        hi  \\\n",
       "GPT 4            19.0  20.0  26.0  26.333333  23.666667  15.0  9.666667   \n",
       "Gemma 2 9B       19.0  20.0  26.0  26.333333  23.666667  15.0  9.666667   \n",
       "Kiwi 22          19.0  20.0  26.0  26.333333  23.666667  15.0  9.666667   \n",
       "Kiwi 23 XL       19.0  20.0  26.0  26.333333  23.666667  15.0  9.666667   \n",
       "Kiwi 23 XXL      19.0  20.0  26.0  26.333333  23.666667  15.0  9.666667   \n",
       "Llama 3.1 70B    19.0  20.0  26.0  26.333333  23.666667  15.0  9.666667   \n",
       "MetricX23 LARGE  19.0  20.0  26.0  26.333333  23.666667  15.0  9.666667   \n",
       "MetricX23 XL     19.0  20.0  26.0  26.333333  23.666667  15.0  9.666667   \n",
       "Mistral 7B       19.0  20.0  26.0  26.333333  23.666667  15.0  9.666667   \n",
       "xCOMET XL        19.0  20.0  26.0  26.333333  23.666667  15.0  9.666667   \n",
       "xCOMET XXL       19.0  20.0  26.0  26.333333  23.666667  15.0  9.666667   \n",
       "\n",
       "                        ru  \n",
       "GPT 4            21.333333  \n",
       "Gemma 2 9B       21.333333  \n",
       "Kiwi 22          21.333333  \n",
       "Kiwi 23 XL       21.333333  \n",
       "Kiwi 23 XXL      21.333333  \n",
       "Llama 3.1 70B    21.333333  \n",
       "MetricX23 LARGE  21.333333  \n",
       "MetricX23 XL     21.333333  \n",
       "Mistral 7B       21.333333  \n",
       "xCOMET XL        21.333333  \n",
       "xCOMET XXL       21.333333  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removed_info = pd.DataFrame(removed_info)\n",
    "removed_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939a40df",
   "metadata": {},
   "source": [
    "Measuring Ties "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f10a3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>ties</th>\n",
       "      <th>ties</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GPT 4</th>\n",
       "      <td>13.750863</td>\n",
       "      <td>7.220292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gemma 2 9B</th>\n",
       "      <td>25.845970</td>\n",
       "      <td>10.795979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kiwi 22</th>\n",
       "      <td>2.955738</td>\n",
       "      <td>4.414397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kiwi 23 XL</th>\n",
       "      <td>2.786005</td>\n",
       "      <td>4.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kiwi 23 XXL</th>\n",
       "      <td>2.975500</td>\n",
       "      <td>4.512605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama 3.1 70B</th>\n",
       "      <td>29.601846</td>\n",
       "      <td>9.800344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MetricX23 LARGE</th>\n",
       "      <td>3.292546</td>\n",
       "      <td>4.982410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MetricX23 XL</th>\n",
       "      <td>4.604977</td>\n",
       "      <td>5.915331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral 7B</th>\n",
       "      <td>73.142166</td>\n",
       "      <td>10.665658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xCOMET XL</th>\n",
       "      <td>3.377789</td>\n",
       "      <td>4.444919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xCOMET XXL</th>\n",
       "      <td>3.558187</td>\n",
       "      <td>4.652427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mean        std\n",
       "                      ties       ties\n",
       "model                                \n",
       "GPT 4            13.750863   7.220292\n",
       "Gemma 2 9B       25.845970  10.795979\n",
       "Kiwi 22           2.955738   4.414397\n",
       "Kiwi 23 XL        2.786005   4.144400\n",
       "Kiwi 23 XXL       2.975500   4.512605\n",
       "Llama 3.1 70B    29.601846   9.800344\n",
       "MetricX23 LARGE   3.292546   4.982410\n",
       "MetricX23 XL      4.604977   5.915331\n",
       "Mistral 7B       73.142166  10.665658\n",
       "xCOMET XL         3.377789   4.444919\n",
       "xCOMET XXL        3.558187   4.652427"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ties = []\n",
    "for (lang, model), subdf in data_all.groupby([\"lang\", \"model\"]):\n",
    "    F_scores = np.array(pd.concat((subdf[\"ref_scores_ff\"],subdf[\"ref_scores_mf\"]),axis=0))\n",
    "    M_scores = np.array(pd.concat((subdf[\"ref_scores_fm\"],subdf[\"ref_scores_mm\"]),axis=0))\n",
    "    ties.append({\"lang\": lang, \"model\": model,\"type\":subdf.iloc[0][\"type\"],\"ties\": 100*(F_scores==M_scores).sum()/len(F_scores)})\n",
    "ties = pd.DataFrame(ties)\n",
    "ties_aggr = pd.pivot_table(ties, \n",
    "                             index='model',  # Pivot by 'full_name'\n",
    "                             values=['ties'], \n",
    "                             aggfunc=['mean','std'])\n",
    "ties_aggr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedd93d5",
   "metadata": {},
   "source": [
    "#### Analysis using continous metrics :\n",
    "  - QE (s_F,h_F) / QE (s_M,h_M)   (mean and stds)\n",
    "  - statistical significance of the ratio (using 1sample ratio test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c5b1a65-4b73-4e86-9f9c-1f542f903178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT 4 ar (229, 12)\n",
      "GPT 4 de (222, 12)\n",
      "GPT 4 es (240, 12)\n",
      "GPT 4 fr (255, 12)\n",
      "GPT 4 hi (271, 12)\n",
      "GPT 4 it (243, 12)\n",
      "GPT 4 pt (221, 12)\n",
      "GPT 4 ru (236, 12)\n",
      "Gemma 2 9B ar (229, 12)\n",
      "Gemma 2 9B de (222, 12)\n",
      "Gemma 2 9B es (240, 12)\n",
      "Gemma 2 9B fr (255, 12)\n",
      "Gemma 2 9B hi (271, 12)\n",
      "Gemma 2 9B it (243, 12)\n",
      "Gemma 2 9B pt (221, 12)\n",
      "Gemma 2 9B ru (236, 12)\n",
      "Kiwi 22 ar (229, 12)\n",
      "Kiwi 22 de (222, 12)\n",
      "Kiwi 22 es (240, 12)\n",
      "Kiwi 22 fr (255, 12)\n",
      "Kiwi 22 hi (271, 12)\n",
      "Kiwi 22 it (243, 12)\n",
      "Kiwi 22 pt (221, 12)\n",
      "Kiwi 22 ru (236, 12)\n",
      "Kiwi 23 XL ar (229, 12)\n",
      "Kiwi 23 XL de (222, 12)\n",
      "Kiwi 23 XL es (240, 12)\n",
      "Kiwi 23 XL fr (255, 12)\n",
      "Kiwi 23 XL hi (271, 12)\n",
      "Kiwi 23 XL it (243, 12)\n",
      "Kiwi 23 XL pt (221, 12)\n",
      "Kiwi 23 XL ru (236, 12)\n",
      "Kiwi 23 XXL ar (229, 12)\n",
      "Kiwi 23 XXL de (222, 12)\n",
      "Kiwi 23 XXL es (240, 12)\n",
      "Kiwi 23 XXL fr (255, 12)\n",
      "Kiwi 23 XXL hi (271, 12)\n",
      "Kiwi 23 XXL it (243, 12)\n",
      "Kiwi 23 XXL pt (221, 12)\n",
      "Kiwi 23 XXL ru (236, 12)\n",
      "Llama 3.1 70B ar (229, 12)\n",
      "Llama 3.1 70B de (222, 12)\n",
      "Llama 3.1 70B es (240, 12)\n",
      "Llama 3.1 70B fr (255, 12)\n",
      "Llama 3.1 70B hi (271, 12)\n",
      "Llama 3.1 70B it (243, 12)\n",
      "Llama 3.1 70B pt (221, 12)\n",
      "Llama 3.1 70B ru (236, 12)\n",
      "MetricX23 LARGE ar (229, 12)\n",
      "MetricX23 LARGE de (222, 12)\n",
      "MetricX23 LARGE es (240, 12)\n",
      "MetricX23 LARGE fr (255, 12)\n",
      "MetricX23 LARGE hi (271, 12)\n",
      "MetricX23 LARGE it (243, 12)\n",
      "MetricX23 LARGE pt (221, 12)\n",
      "MetricX23 LARGE ru (236, 12)\n",
      "MetricX23 XL ar (229, 12)\n",
      "MetricX23 XL de (222, 12)\n",
      "MetricX23 XL es (240, 12)\n",
      "MetricX23 XL fr (255, 12)\n",
      "MetricX23 XL hi (271, 12)\n",
      "MetricX23 XL it (243, 12)\n",
      "MetricX23 XL pt (221, 12)\n",
      "MetricX23 XL ru (236, 12)\n",
      "Mistral 7B ar (229, 12)\n",
      "Mistral 7B de (222, 12)\n",
      "Mistral 7B es (240, 12)\n",
      "Mistral 7B fr (255, 12)\n",
      "Mistral 7B hi (271, 12)\n",
      "Mistral 7B it (243, 12)\n",
      "Mistral 7B pt (221, 12)\n",
      "Mistral 7B ru (236, 12)\n",
      "xCOMET XL ar (229, 12)\n",
      "xCOMET XL de (222, 12)\n",
      "xCOMET XL es (240, 12)\n",
      "xCOMET XL fr (255, 12)\n",
      "xCOMET XL hi (271, 12)\n",
      "xCOMET XL it (243, 12)\n",
      "xCOMET XL pt (221, 12)\n",
      "xCOMET XL ru (236, 12)\n",
      "xCOMET XXL ar (229, 12)\n",
      "xCOMET XXL de (222, 12)\n",
      "xCOMET XXL es (240, 12)\n",
      "xCOMET XXL fr (255, 12)\n",
      "xCOMET XXL hi (271, 12)\n",
      "xCOMET XXL it (243, 12)\n",
      "xCOMET XXL pt (221, 12)\n",
      "xCOMET XXL ru (236, 12)\n",
      "model                     False\n",
      "lang                      False\n",
      "ref_score_M_mean          False\n",
      "ref_score_F_mean          False\n",
      "ref_score_M_std           False\n",
      "ref_score_F_std           False\n",
      "ref_ratio_mean            False\n",
      "ref_ratio_std             False\n",
      "ref_significance_ratio    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "stats_list = list()\n",
    "for (model, lang), subdf in data_all.groupby([\"model\",\"lang\"]):\n",
    "\n",
    "    ##  FF-MM comparison with continuous metrics! REFERENCES!!!\n",
    "    REF_ratios,_,REF_ratio_1sampl_test = eval_metrics.Ratio({\"F\": subdf[\"ref_scores_ff\"], \"M\": subdf[\"ref_scores_mm\"]}).score()\n",
    "    # REF_diff,_,REF_diff_wilc_test = metrics.DifferenceWilcoxon({\"F\": subdf[\"ref_scores_ff\"], \"M\": subdf[\"ref_scores_mm\"]}).score()\n",
    "    print(model,lang,subdf.shape)\n",
    "    \n",
    "    d = dict(\n",
    "        model=model,\n",
    "        lang=lang,\n",
    "        ref_score_M_mean=subdf[\"ref_scores_mm\"].mean(),\n",
    "        ref_score_F_mean=subdf[\"ref_scores_ff\"].mean(),\n",
    "        ref_score_M_std=subdf[\"ref_scores_mm\"].std(),\n",
    "        ref_score_F_std=subdf[\"ref_scores_ff\"].std(),\n",
    "        ref_ratio_mean = REF_ratios.mean(),\n",
    "        ref_ratio_std = REF_ratios.std(),\n",
    "        ref_significance_ratio = REF_ratio_1sampl_test  \n",
    "    )\n",
    "    stats_list.append(d)\n",
    "\n",
    "stats_df = pd.DataFrame(stats_list).reset_index()\n",
    "stats_df = stats_df.drop('index',axis=1)\n",
    "\n",
    "# check for None values:\n",
    "print(stats_df.isnull().any())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140f194b",
   "metadata": {},
   "source": [
    "Save the corresponding metrics computed + statistical significance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e56ecf5-ee97-45b7-864f-f3b6c6bdc4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### save the corresponding metrics computed for all metrics\n",
    "stats_path = './results-copied/stats/nonambiguous-counterfactual/references/continuous-analysis/results.csv'\n",
    "os.makedirs(os.path.dirname(stats_path), exist_ok=True)\n",
    "stats_df.to_csv(stats_path, index=False)\n",
    "\n",
    "ratio_test_path= './results-copied/stats/nonambiguous-counterfactual/references/continuous-analysis/significance_test_ratio.csv'\n",
    "os.makedirs(os.path.dirname(ratio_test_path), exist_ok=True)\n",
    "significance_test_ratio_QE = stats_df.pivot_table(index=[\"model\"],columns=[\"lang\"],\n",
    "                              values=[\"ref_significance_ratio\"])\n",
    "significance_test_ratio_QE.to_csv(ratio_test_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aa9e5b",
   "metadata": {},
   "source": [
    "### Prediction-based Analysis\n",
    "In this part we compute the results for the prediction-based analysis (per language) :\n",
    "- Total Error Rate\n",
    "- ER(S^F) , ER(S^M)  \n",
    "- Ratio Î¦ = ER(S^F) / ER(S^M)\n",
    "- Statistical Significance for ER(S^F) / ER(S^M) (per language)  (Using bootstrap resampling )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac9458d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'source_feminine', 'reference_feminine', 'source_masculine',\n",
       "       'reference_masculine', 'ref_scores_ff', 'ref_scores_fm',\n",
       "       'ref_scores_mf', 'ref_scores_mm', 'model', 'lang', 'type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8dbc579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar GPT 4 (229, 12)\n",
      "de GPT 4 (222, 12)\n",
      "es GPT 4 (240, 12)\n",
      "fr GPT 4 (255, 12)\n",
      "hi GPT 4 (271, 12)\n",
      "it GPT 4 (243, 12)\n",
      "pt GPT 4 (221, 12)\n",
      "ru GPT 4 (236, 12)\n",
      "ar Gemma 2 9B (229, 12)\n",
      "de Gemma 2 9B (222, 12)\n",
      "es Gemma 2 9B (240, 12)\n",
      "fr Gemma 2 9B (255, 12)\n",
      "hi Gemma 2 9B (271, 12)\n",
      "it Gemma 2 9B (243, 12)\n",
      "pt Gemma 2 9B (221, 12)\n",
      "ru Gemma 2 9B (236, 12)\n",
      "ar Kiwi 22 (229, 12)\n",
      "de Kiwi 22 (222, 12)\n",
      "es Kiwi 22 (240, 12)\n",
      "fr Kiwi 22 (255, 12)\n",
      "hi Kiwi 22 (271, 12)\n",
      "it Kiwi 22 (243, 12)\n",
      "pt Kiwi 22 (221, 12)\n",
      "ru Kiwi 22 (236, 12)\n",
      "ar Kiwi 23 XL (229, 12)\n",
      "de Kiwi 23 XL (222, 12)\n",
      "es Kiwi 23 XL (240, 12)\n",
      "fr Kiwi 23 XL (255, 12)\n",
      "hi Kiwi 23 XL (271, 12)\n",
      "it Kiwi 23 XL (243, 12)\n",
      "pt Kiwi 23 XL (221, 12)\n",
      "ru Kiwi 23 XL (236, 12)\n",
      "ar Kiwi 23 XXL (229, 12)\n",
      "de Kiwi 23 XXL (222, 12)\n",
      "es Kiwi 23 XXL (240, 12)\n",
      "fr Kiwi 23 XXL (255, 12)\n",
      "hi Kiwi 23 XXL (271, 12)\n",
      "it Kiwi 23 XXL (243, 12)\n",
      "pt Kiwi 23 XXL (221, 12)\n",
      "ru Kiwi 23 XXL (236, 12)\n",
      "ar Llama 3.1 70B (229, 12)\n",
      "de Llama 3.1 70B (222, 12)\n",
      "es Llama 3.1 70B (240, 12)\n",
      "fr Llama 3.1 70B (255, 12)\n",
      "hi Llama 3.1 70B (271, 12)\n",
      "it Llama 3.1 70B (243, 12)\n",
      "pt Llama 3.1 70B (221, 12)\n",
      "ru Llama 3.1 70B (236, 12)\n",
      "ar MetricX23 LARGE (229, 12)\n",
      "de MetricX23 LARGE (222, 12)\n",
      "es MetricX23 LARGE (240, 12)\n",
      "fr MetricX23 LARGE (255, 12)\n",
      "hi MetricX23 LARGE (271, 12)\n",
      "it MetricX23 LARGE (243, 12)\n",
      "pt MetricX23 LARGE (221, 12)\n",
      "ru MetricX23 LARGE (236, 12)\n",
      "ar MetricX23 XL (229, 12)\n",
      "de MetricX23 XL (222, 12)\n",
      "es MetricX23 XL (240, 12)\n",
      "fr MetricX23 XL (255, 12)\n",
      "hi MetricX23 XL (271, 12)\n",
      "it MetricX23 XL (243, 12)\n",
      "pt MetricX23 XL (221, 12)\n",
      "ru MetricX23 XL (236, 12)\n",
      "ar Mistral 7B (229, 12)\n",
      "de Mistral 7B (222, 12)\n",
      "es Mistral 7B (240, 12)\n",
      "fr Mistral 7B (255, 12)\n",
      "hi Mistral 7B (271, 12)\n",
      "it Mistral 7B (243, 12)\n",
      "pt Mistral 7B (221, 12)\n",
      "ru Mistral 7B (236, 12)\n",
      "ar xCOMET XL (229, 12)\n",
      "de xCOMET XL (222, 12)\n",
      "es xCOMET XL (240, 12)\n",
      "fr xCOMET XL (255, 12)\n",
      "hi xCOMET XL (271, 12)\n",
      "it xCOMET XL (243, 12)\n",
      "pt xCOMET XL (221, 12)\n",
      "ru xCOMET XL (236, 12)\n",
      "ar xCOMET XXL (229, 12)\n",
      "de xCOMET XXL (222, 12)\n",
      "es xCOMET XXL (240, 12)\n",
      "fr xCOMET XXL (255, 12)\n",
      "hi xCOMET XXL (271, 12)\n",
      "it xCOMET XXL (243, 12)\n",
      "pt xCOMET XXL (221, 12)\n",
      "ru xCOMET XXL (236, 12)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prediction_list = list()\n",
    "for (model, lang), subdf in data_all.groupby([\"model\",\"lang\"]):\n",
    "    print(lang,model,subdf.shape)\n",
    "    F_scores = np.array(pd.concat((subdf[\"ref_scores_ff\"],subdf[\"ref_scores_mf\"]),axis=0))\n",
    "    M_scores = np.array(pd.concat((subdf[\"ref_scores_fm\"],subdf[\"ref_scores_mm\"]),axis=0))\n",
    "    ground_truth = np.concatenate((np.array([\"female\" for i in range(subdf[\"ref_scores_ff\"].shape[0])]), np.array([\"male\" for i in range(subdf[\"ref_scores_mm\"].shape[0])])),axis=0)\n",
    "    ref_acc = eval_metrics.Accuracy({\"F\": F_scores, \"M\": M_scores,\"y_true\": ground_truth}).score()\n",
    "    ref_group_metrics = eval_metrics.GroupMetricsBootstraping({\"F\": F_scores, \"M\": M_scores,\"y_true\": ground_truth},alternative=\"greater\").stat_significance_with_paired_bootstrap()\n",
    "\n",
    "    d = dict(\n",
    "        model=model,\n",
    "        lang=lang,\n",
    "        ref_acc_total = ref_acc,\n",
    "        ref_error_rate_total = ref_group_metrics[\"results\"][\"total_error_rate\"],\n",
    "        ref_error_rate_male = ref_group_metrics[\"results\"][\"male\"][\"fnr\"],\n",
    "        ref_error_rate_fem =ref_group_metrics[\"results\"][\"female\"][\"fnr\"],\n",
    "        ref_error_rate_ratio =  ref_group_metrics[\"results\"][\"fnr_ratio\"],\n",
    "        ref_stat_significance = ref_group_metrics[\"stat_significance\"],\n",
    "    )\n",
    "\n",
    "    prediction_list.append(d)\n",
    "prediction_df = pd.DataFrame(prediction_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc9fe5b",
   "metadata": {},
   "source": [
    "check for None values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5eeacdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model                    False\n",
       "lang                     False\n",
       "ref_acc_total            False\n",
       "ref_error_rate_total     False\n",
       "ref_error_rate_male      False\n",
       "ref_error_rate_fem       False\n",
       "ref_error_rate_ratio     False\n",
       "ref_stat_significance    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08e1a7a",
   "metadata": {},
   "source": [
    "We save all the corresponding metrics computed (per-language)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0daf4d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df_path = './results-copied/stats/nonambiguous-counterfactual/references/prediction-analysis/data.csv'\n",
    "os.makedirs(os.path.dirname(acc_df_path), exist_ok=True)\n",
    "prediction_df.to_csv(acc_df_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
